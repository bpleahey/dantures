{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013d5a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/bpleahey/thesis.git\n",
    "%cd thesis\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa27543",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure you've returned to the root directory\n",
    "\n",
    "%ls\n",
    "\n",
    "# % cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c310ccb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# download dataset to content folder\n",
    "\n",
    "!mkdir -p /content/data\n",
    "\n",
    "# download train set\n",
    "# change wget to my google drive folder i produce\n",
    "!wget -P /content/data -o content/data/elevation.zip https://zenodo.org/records/7591134/files/elevation%20data.zip?download=1\n",
    "!unzip -q /content/data/elevation.zip -d /content/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078fe27",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# restructure train data to prep for inference\n",
    "\n",
    "!mkdir -p /content/data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f898e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: write a filepath to replace truck where images are read from, and a filepath to replace results_truck where images are written to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ed37f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: for early-fusion method, call adaptive gating method on all train/val/test images here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a88dce3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# augment dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import gaussian_laplace\n",
    "from scipy.ndimage import gaussian_gradient_magnitude\n",
    "from scipy.ndimage import gaussian_laplace\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "lists = os.listdir(truck) #Where to read files from, rename truck to the folder you want to read from\n",
    "files = len(lists) #Count the number of files and return it as interger to be used in the loop\n",
    "for i in range(files):\n",
    "    try:\n",
    "        image = imageio.imread(truck+str(i)+'.jpg')\n",
    "        \n",
    "        #flipped, blurred, flipped+blurred\n",
    "\n",
    "        flipped_images = cv2.flip(image, 1);\n",
    "        blurred_images =  np.hstack([cv2.GaussianBlur(image, (29, 29), 0)])\n",
    "        flipped_blurred_images = np.hstack([cv2.GaussianBlur(flipped_images, (39, 39), 0)])\n",
    "        cv2.imwrite(results_truck+str(i)+'truck.jpg',cv2.cvtColor(image, cv2.COLOR_RGB2BGR));\n",
    "        cv2.imwrite(results_truck+str(i)+'truck_flipped_images.jpg',cv2.cvtColor(flipped_images, cv2.COLOR_RGB2BGR));\n",
    "        cv2.imwrite(results_truck+str(i)+'truck_blurred_images.jpg',cv2.cvtColor(blurred_images, cv2.COLOR_RGB2BGR));\n",
    "        cv2.imwrite(results_truck+str(i)+'truck_flipped_blurred.jpg',cv2.cvtColor(flipped_blurred_images, cv2.COLOR_RGB2BGR));\n",
    "        \n",
    "        #sobelxy filter\n",
    "        image = imageio.imread(truck+str(i)+'.jpg')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        sobelX = cv2.Sobel(image, cv2.CV_64F, 1, 0)\n",
    "        sobelY = cv2.Sobel(image, cv2.CV_64F, 0, 1)\n",
    "        sobelX = np.uint8(np.absolute(sobelX))\n",
    "        sobelY = np.uint8(np.absolute(sobelY))\n",
    "        sobelCombined = cv2.bitwise_or(sobelX, sobelY)\n",
    "        cv2.imwrite(results_truck+str(i)+'truck_sobel_xy.jpg',cv2.cvtColor(sobelCombined, cv2.COLOR_RGB2BGR));\n",
    "       \n",
    "       #DoG filter\n",
    "        amg = imageio.imread(truck+str(i)+'.jpg', as_gray=True).astype(np.uint8)\n",
    "        bmg = DoGFilter(amg, 2, 4)\n",
    "        cv2.imwrite(results_truck+str(i)+'truck_dog.jpg',cv2.cvtColor(bmg, cv2.COLOR_RGB2BGR));\n",
    "\n",
    "        #Gaussian thresholding filter\n",
    "        image = imageio.imread(truck+str(i)+'.jpg')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\n",
    "        cv2.imwrite(results_truck+str(i)+'truck_gauss_thresh.jpg',cv2.cvtColor(thresh, cv2.COLOR_RGB2BGR));\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b260fb4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess data for yolo compatibility\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from processing import preprocess\n",
    "\n",
    "lists = os.listdir(truck) #Where to read files from\n",
    "files = len(lists) #Count the number of files and return it as interger to be used in the loop\n",
    "for i in range(files):\n",
    "    try:\n",
    "        image = imageio.imread(truck + str(i) + '.jpg')\n",
    "        image = preprocess(image, (640, 640))  # Resize to 640x640 and apply any other needed preprocessing\n",
    "        cv2.imwrite(truck + str(i) + '.jpg', image)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {i}: {e}\")\n",
    "\n",
    "#TODO: also carry out for val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737c354",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# restructure content folder to have a weights folder\n",
    "!mkdir -p /content/weights\n",
    "wget -P /content/weights/ https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925be9ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# configure wandb\n",
    "import os\n",
    "\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "!wandb login WANDB_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d8e99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "% cd /content/thesis\n",
    "# train baseline model on RGB images\n",
    "\n",
    "# freeze 28 corresponds to the 28 backbone layers of the model\n",
    "!python train.py --img 640 --batch 16 --epochs 50 --data data.yaml --cfg models/yolov7-tiny.yaml --weights yolov7-tiny.pt --hyp hyp.scratch.custom.yaml --freeze 28 --name rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8745e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python test.py --img 640 --batch 16 --data data.yaml --cfg models/yolov7-tiny.yaml --device=0 --weights <path from runs/train/expx> --conf 0.1 --iou 0.65 --name rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc16070",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: correct paths\n",
    "from IPython.display import Image\n",
    "display(Image(\"/content/gdrive/MyDrive/yolov7/runs/train/exp4/F1_curve.png\", width=400, height=400)) # correct path\n",
    "display(Image(\"/content/gdrive/MyDrive/yolov7/runs/train/exp4/PR_curve.png\", width=400, height=400))\n",
    "display(Image(\"/content/gdrive/MyDrive/yolov7/runs/train/exp4/confusion_matrix.png\", width=500, height=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c28366",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights <path from runs/train/expx/weights/best.pt> --conf 0.1 --img-size 640 --source <path to test images>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
